# -*- coding: utf-8 -*-
"""SoilCompatiblity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XnofU1E1M3ftGn9kduGcxpK9PAOOTLMn
"""



from google.colab import drive
drive.mount('/content/drive')

import numpy as np

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

df = pd.read_csv('/content/Soil-Climate-data.csv')

df.head(10)

df.isna().sum()

df.info()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df['Crop_Type'] = le.fit_transform(df['Crop_Type'])

df['Soil_Type'] = le.fit_transform(df['Soil_Type'])

df.info()

plt.figure(figsize=(15,15))
sns.heatmap(df.corr(),annot=True)

from sklearn.model_selection import train_test_split

X = df.drop('Compatible',axis=1)
y = df['Compatible']

from imblearn.over_sampling import SMOTE

# Apply SMOTE to oversample the minority class
smote = SMOTE(random_state=42)  # You can adjust random_state
X_resampled, y_resampled = smote.fit_resample(X, y)

from sklearn.preprocessing import MaxAbsScaler

# prompt: cide for MaxAbsScaler for X and y

scaler = MaxAbsScaler()
X_scaled = scaler.fit_transform(X_resampled)
y_scaled = scaler.fit_transform(y_resampled.values.reshape(-1,1))

# prompt: help me with smote to nullify imbalance

from imblearn.over_sampling import SMOTE

# Separate features (X) and target variable (y)
X = df.drop('Compatible', axis=1)
y = df['Compatible']

# Apply SMOTE to oversample the minority class
smote = SMOTE(random_state=42)  # You can adjust random_state
X_resampled, y_resampled = smote.fit_resample(X, y)

# Now X_resampled and y_resampled contain the balanced dataset
# You can proceed with your model training using these resampled datasets

# Example: Splitting the resampled data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.25, random_state=42)

from sklearn.naive_bayes import MultinomialNB
mb = MultinomialNB()

mb.fit(X_train,y_train)

y_pred = mb.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print(accuracy_score(y_test,y_pred))

print(classification_report(y_test,y_pred))

# prompt: code for standard scaler

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_resampled)
y_scaled = scaler.fit_transform(y_resampled.values.reshape(-1,1))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.33, random_state=42)

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(X_train,y_train)

y_pred_dt = dt.predict(X_test)

print(accuracy_score(y_test,y_pred_dt))
print(classification_report(y_test,y_pred_dt))

print(confusion_matrix(y_test,y_pred_dt))

from sklearn.dummy import DummyClassifier

dummy = DummyClassifier(strategy='most_frequent')
dummy.fit(X_train, y_train)
y_pred_dummy = dummy.predict(X_test)

print(accuracy_score(y_test,y_pred_dummy))
print(classification_report(y_test,y_pred_dummy))

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train,y_train)

y_pred_lr = lr.predict(X_test)

print(accuracy_score(y_test,y_pred_lr))
print(classification_report(y_test,y_pred_lr))

!pip show lazy-predict

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred1 = rf.predict(X_test)

print(accuracy_score(y_test,y_pred1))
print(classification_report(y_test,y_pred1))

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

y_pred_knn = knn.predict(X_test)

print(accuracy_score(y_test,y_pred_knn))
print(classification_report(y_test,y_pred_knn))

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier()
gb.fit(X_train,y_train)

y_pred4 = gb.predict(X_test)

print(accuracy_score(y_test,y_pred4))
print(classification_report(y_test,y_pred4))

"""# **Meta Learning with fewshot adaptation**


"""

